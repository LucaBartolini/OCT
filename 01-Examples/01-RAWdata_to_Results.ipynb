{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## imports\n",
    "import os \n",
    "\n",
    "# import numpy as np\n",
    "# import cv2 as cv\n",
    "import json\n",
    "from datetime import datetime  \n",
    "\n",
    "# %matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from skimage import data, img_as_float\n",
    "# from skimage.segmentation import (morphological_chan_vese, checkerboard_level_set)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport OCT_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 files \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Files management\n",
    "## You may provide the `path` to the folder with all the binary files\n",
    "# initial_path = r\"C:\\Users\\user\\Google Drive\\01 - OCT\\Measurements\\20190708_CscanThumbRel\"\n",
    "# initial_path = r\"C:\\Users\\lucab\\Desktop\\20190718_PDMS_Sample20180219_2\"\n",
    "initial_path = r\"/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\"\n",
    "\n",
    "if 'initial_path' in locals():\n",
    "    files, _ = OCT_lib.get_files(directory = initial_path) \n",
    "else:\n",
    "    # if `initial_path` is not provided, a selector windows will appear (sometimes under the browser) \n",
    "    files, initial_path = OCT_lib.get_files()\n",
    "    \n",
    "folder_name = os.path.basename(os.path.normpath(initial_path))\n",
    "\n",
    "## rolling the list of files \n",
    "## e.g.: if when acquiring a C-scan, the first slice of the intended output C-scan was saved by \n",
    "## LabView in position 74, use N_roll = 74\n",
    "## (this part will be worked out on the LabView side)\n",
    "N_roll = 0 #230\n",
    "if N_roll:\n",
    "    print(f\"WARNING: the ordering of the files has been changed. \\nThe first file analyzed is now B-scan #{N_roll}\") \n",
    "    OCT_lib.roll_list(files, N_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing only the first three files\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing only the first three files\")\n",
    "# files = files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters used for this analysis are specified in the Jupyter Notebook\n",
      "===================\n",
      "Following settings are non-default:\n",
      "\n",
      "p[save_png]=False DIFFERENT FROM Default_Settings[save_png](=True)\n",
      "p[save_settings]=False DIFFERENT FROM Default_Settings[save_settings](=True)\n",
      "\n",
      "===================\n",
      "Analysis settings: \n",
      "===================\n",
      "    Cropping is OFF\n",
      "    Resizing is OFF\n",
      "   Filtering is ON\n",
      "Segmentation is ON\n",
      " .png making is OFF\n",
      "    Savefile is ON\n"
     ]
    }
   ],
   "source": [
    "### Analysis parameters\n",
    "\n",
    "# will show a bit more information during the execution of the code\n",
    "debug_here = False \n",
    "\n",
    "# default parameters are stored in OCT_lib.py\n",
    "default_analysis_settings = False\n",
    "# if enabled, prompts the selection of a txt files with the analysis parameters in JSON format\n",
    "read_parameters_from_file = False\n",
    "\n",
    "if default_analysis_settings:\n",
    "    p = OCT_lib.default_settings\n",
    "    print(f\"The parameters used for this analysis are the default ones\")\n",
    "elif read_parameters_from_file:\n",
    "    param_textfile = f\"{os.path.join(initial_path,'processed')}\\\\parameters.txt\"\n",
    "#     param_textfile = OCT_lib.get_file(initdir = initial_path, ext='txt')\n",
    "    print(f\"The parameters used for this analysis are being taken from: \\n{param_textfile}\") \n",
    "    with open(param_textfile, 'r') as file:\n",
    "        p = json.loads(file.read()) \n",
    "else:\n",
    "    print(f\"The parameters used for this analysis are specified in the Jupyter Notebook\") \n",
    "    ## dictionary will all the parameters for the analysis\n",
    "    p = dict(\n",
    "        ## if crop['switch'] is True, the image gets cropped at the specified indices \n",
    "        crop = dict(\n",
    "            # turn the crop switch ON or OFF\n",
    "            switch = False,\n",
    "            ## cropping indices\n",
    "            left = None,\n",
    "            right = None,\n",
    "            top = None,\n",
    "            bottom = None,\n",
    "        ),\n",
    "        ## if resize['switch'] is True, the image gets resized with the specified factors \n",
    "        resize = dict(\n",
    "            switch = False,\n",
    "            width_factor = 1,\n",
    "            height_factor = 1,\n",
    "        ),\n",
    "        ## filter_settings contains all the parameters of each filtering mode \n",
    "        filtering = dict(\n",
    "                switch = True, # Turns filtering ON or OFF \n",
    "                mode = 'bilateral', # filtering mode: set to `NLM` or `bilateral`\n",
    "                bilateral = dict(\n",
    "                    d = 15,\n",
    "                    sigma_color = 90,\n",
    "                    sigma_space = 80,\n",
    "                ),\n",
    "                NLM = dict(\n",
    "                    sigma = 6, #parameter for NLM denoising\n",
    "                ),\n",
    "            ),\n",
    "        ## Parameters of segmentation\n",
    "        segmentation = dict(\n",
    "            switch = True, \n",
    "            mode = \"otsu\", # or  \"chan_vese\"\n",
    "            ignore_top_px = 150,\n",
    "            N_iter = 20, # used in ACWE segm. (see docs of `morphological snakes`)\n",
    "        ),\n",
    "        ## Parameters of Axsun OCT\n",
    "        OCT = dict(\n",
    "            axial_res = 5.75, # Vertical Resolution of OCT, in micron per pixel\n",
    "            aperture_size = 4, # size of the suction aperture\n",
    "            bypassmode = 8, # this translates to how many bytes per px  (defaul 1b/px): See Axsun manual\n",
    "        ),           \n",
    "        save_png = False, # saves B-scans in .png format in folder \\processed\n",
    "        make_res = True, # stores all processing results in a dictionary\n",
    "        save_zip = True, # saves that dictionary in a pickled .bz2 \n",
    "        save_settings = False, # saves analysis settings in a JSON file\n",
    "    )\n",
    "\n",
    "print(OCT_lib.print_about_settings(p))\n",
    "      \n",
    "if p['save_zip']:         \n",
    "     assert p['make_res'], \\\n",
    "        \"Zip file contents are based on the stored results, please set `True` the p['make_res'] switch\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     79
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File \"2boundary_rel\" - 1/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\2boundary_rel\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"2boundary_rel\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"2boundary_suc\" - 2/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\2boundary_suc\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"2boundary_suc\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"2thick_rel\" - 3/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\2thick_rel\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"2thick_rel\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"2thick_suc\" - 4/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\2thick_suc\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"2thick_suc\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"2thin_rel\" - 5/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\2thin_rel\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"2thin_rel\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"2thin_suc\" - 6/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\2thin_suc\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"2thin_suc\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"boundary_rel\" - 7/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\boundary_rel\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"boundary_rel\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"boundary_suc\" - 8/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\boundary_suc\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"boundary_suc\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"thick_rel\" - 9/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\thick_rel\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"thick_rel\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"thick_suc\" - 10/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\thick_suc\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"thick_suc\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"thin_rel\" - 11/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\thin_rel\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"thin_rel\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "File \"thin_suc\" - 12/12\n",
      "/Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\thin_suc\n",
      "Bypass not specified, will read the binary in chunks of 1 byte\n",
      "\"thin_suc\" loaded.\n",
      " - 1024x636px, bypass: 8\n",
      "\n",
      "Saving file at path: /Users/lucab/Google Drive/01 - OCT/Measurements/20190410 - step PDMS 2\\processed\\20190410 - step PDMS 2_20191017_09-47_processed.bz2\n"
     ]
    }
   ],
   "source": [
    "# initialization of the dictionary that will store the processed results\n",
    "if p['make_res']:\n",
    "    res = dict.fromkeys(files)\n",
    "\n",
    "# creates folder `processed` in which to save B-scans, parameters file and/or zip file\n",
    "if (p['save_png'] or p['save_zip']):\n",
    "    if not os.path.exists(os.path.join(initial_path, 'processed')):\n",
    "        os.makedirs(os.path.join(initial_path, 'processed'))\n",
    "\n",
    "# ==== START cycling over the files ====\n",
    "for i, file in enumerate(files[:]):\n",
    "    print(f'File \"{file}\" - {i+1}/{len(files)}')\n",
    "    path2file = os.path.join(initial_path, file)\n",
    "    print(path2file)\n",
    "    # load file\n",
    "    b = OCT_lib.bscan(path=path2file, debug=debug_here)\n",
    "\n",
    "    # crop\n",
    "    if p['crop']['switch']:\n",
    "        b.crop(top=p['crop']['top'],\n",
    "               bottom=p['crop']['bottom'],\n",
    "               left=p['crop']['left'],\n",
    "               right=p['crop']['right'])\n",
    "\n",
    "    ## halves the size - used for 3D volumetric visualization:\n",
    "    if p['resize']['switch']:\n",
    "        b.resize_raw(w=b.width * p['resize']['width_factor'],\n",
    "                     h=b.ascanlength * p['resize']['height_factor'])\n",
    "\n",
    "    ## filters the image if required\n",
    "    if p['filtering']['mode']:\n",
    "        # The next line is a bit complicated. Apply_filter takes in some keyword arguments\n",
    "        # that are packed into the settings dictionary p['filtering'][filtermode]\n",
    "        b.apply_filter(mode=p['filtering']['mode'],\n",
    "                       **p['filtering'][p['filtering']['mode']])\n",
    "\n",
    "    ## Surface identification, returns a 1D array with the height of the surface\n",
    "    if p['segmentation']['switch']:\n",
    "        profile = b.get_profile(mode=p['segmentation']['mode'],\n",
    "                                exclude_top_px=p['segmentation']['ignore_top_px'])\n",
    "\n",
    "    ## To obtain the 2D mask (called levelset), use:\n",
    "#         levelset = b.get_level_set(mode='otsu')\n",
    "\n",
    "    if p['make_res']:\n",
    "        res[file] = {}\n",
    "        res[file]['image'] = b.raw\n",
    "        # relaxed or suction?\n",
    "        if 'suc' in file:\n",
    "            res[file]['pressure'] = 'suction'\n",
    "        elif 'rel' in file:\n",
    "            res[file]['pressure'] = 'relaxed'\n",
    "\n",
    "        if p['segmentation']['switch']:\n",
    "            if 'profile' in locals():\n",
    "                # 1D array of skin height along the B-scan\n",
    "                res[file]['profile'] = profile\n",
    "            if 'levelset' in locals():\n",
    "                # B&W image returned by segmentation\n",
    "                res[file]['levelset'] = levelset\n",
    "\n",
    "    # saving png image\n",
    "    if p['save_png']:\n",
    "        png_name = file\n",
    "        profile = profile if p['segmentation']['switch'] else None\n",
    "        b.save_png(\n",
    "            name=png_name,\n",
    "            profile=profile,\n",
    "        )\n",
    "# === END OF FILEs CYCLING ===\n",
    "\n",
    "# Reads the time at which the analysis has been executed\n",
    "analysis_time = datetime.now().strftime(\"%Y%m%d_%H-%M\")\n",
    "\n",
    "# also save analysis parameters in a .txt file (for further use)\n",
    "if p['save_settings']:\n",
    "    settings_filename = f\"{analysis_time}_parameters.txt\"\n",
    "    settings_pathfile = os.path.join(\n",
    "        initial_path, 'processed', settings_filename)\n",
    "    print(\n",
    "        f\"The parameters used for this analysis have been written at: \\n{settings_pathfile}\")\n",
    "    with open(settings_pathfile, 'w') as file: \n",
    "        # use `json.loads` to do the reverse\n",
    "        file.write(json.dumps(p, indent=3))\n",
    "\n",
    "# save all processed data in a zip file\n",
    "if p['save_zip']:\n",
    "    experiment = {}\n",
    "    experiment['results'] = res\n",
    "    experiment['params'] = p\n",
    "    experiment['name'] = folder_name \n",
    "    import bz2  # to zip the pickle file:\n",
    "    import pickle\n",
    "#     pickle_name = (os.path.join(initial_path,'processed'))+'\\\\'+folder_name'+'_processed.bz2'\n",
    "#     pickle_name = f\"{os.path.join(initial_path,'processed')}\\\\{folder_name}_{analysis_time}_processed.bz2\"\n",
    "    pickle_name = os.path.join(initial_path,'processed',f\"{folder_name}_{analysis_time}_processed.bz2\")   \n",
    "    print(f\"Saving file at path: {pickle_name}\")\n",
    "    sfile = bz2.BZ2File(pickle_name, 'w')\n",
    "    pickle.dump(experiment, sfile)\n",
    "    sfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[files[1]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['results', 'params', 'name'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
